# Lay Summarization- BioNLP
We have used a pre-trained language model (PLM) to train a system that produces a laymanâ€™s summary given a research publication from the biomedical domain.<br>
We have also participated in a related competition BioLaysumm, hosted by BioNLP Workshop, ACL 2024 (https://www.codabench.org/competitions/1920/). Our submission (userid- lkm1ml) was in the top 10 at the time of this submission to the competition.

## This repository contains:
-**flant5-finetune.py** - Training code to finetune a FLAN-T5 model <br>
-**flant5-inference.py** - A code used to do inference with the model <br>
-**run_model.sh** - Entry point for model training and inference. <br>
-**writeup.txt** - A text file listing your approach, results and settings of experiments  <br>
-**plos.txt and elife.txt** - Outputs generated on the test data.<br>
-**link.txt** - A link to the Google Drive folder containing the trained model <br>
-**screenshot.jpg** -  a screenshot of our submission to CodaBench<br>
-**prediction_result.zip** - predicted results on the test data that is submitted to CodaBench<br>
-**requirements.txt** - installation requirements to create a required environment. Other required thing will be pre-installed or cached in the environment

## DECLARATION
<!-- **DECLARATION** <br> -->
This work was done collaboratively by Tanishq and Lalit during COL772, Natural Language Processing course (Spring 2024,Prof. Mausam, IIT Delhi).

